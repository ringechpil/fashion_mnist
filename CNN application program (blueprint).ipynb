{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "\n",
    "Write a demo program to apply CNN model on camera / video frames and record your results into videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Blueprint\n",
    "\n",
    "Here I will provide just a blueprint of the required program. I wasn't able to come out with a way to make an object detector based on a custom made CNN. Also, I haven't been able to find a proper resource on the internet to do so. The resources I was able to find were based on some pre-made architectures and algorithms such as ResNet, VGG, SSD, Yolo and so on...  This blueprint might also seem a bit naive, since it first 'does' the detection and then the classification, while in practice, both things are done simultaneously.  \n",
    "\n",
    "Hopefully, given the opportunity, learning to do this properly would be amnong the first to-learn tasks during my internship.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the class names\n",
    "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the incomplete function that takes a frame as an argument,\n",
    "turns it grayscale, detects and classifies the objects within\n",
    "the frame. \n",
    "'''\n",
    "\n",
    "def obj_detector(frame, cnn):\n",
    "    \n",
    "    #first, we turn the frame into grayscale\n",
    "    cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    images = []\n",
    "    img_coords = []\n",
    "    \n",
    "    '''\n",
    "    Let's assume that we have managed somehow to get the objects\n",
    "    of interest from the frame, and that we have stored them in the\n",
    "    images list, which is a list of 2D numpy arrays. We also have \n",
    "    another list - img_coords, which is a list of 4-tuples \n",
    "    containing the coorinates of an image within a frame. \n",
    "    '''\n",
    "   \n",
    "\n",
    "    for image, coords in zip(images, img_coords):\n",
    "    \n",
    "        #resizing, adding the channel axis and scaling to [0,1]\n",
    "        image = cv2.resize(image, (28, 28))\n",
    "        #maybe I should also add a channel, but not sure...\n",
    "        #image = np.expand_dims(image, axis = 2)\n",
    "        image = image.astype('float')\n",
    "        image = image/255\n",
    "        \n",
    "        #predicting the class of an image \n",
    "        image = np.expand_dims(image, axis = 0)\n",
    "        class_no = cnn.predict_classes(image)[0]\n",
    "        pred_class = class_labels[class_no]\n",
    "        \n",
    "        #drawing a rectangle around an image\n",
    "        cv2.rectangle(frame, (coords[0], coords[1]),\n",
    "                     (coords[2], coords[3]),\n",
    "                     (0,255,0))\n",
    "        \n",
    "        \n",
    "        #labeling the image\n",
    "        cv2.putText(frame, pred_class, (coords[0], coords[1]))\n",
    "        \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to load a pretrained CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten\n",
    "from keras.optimizers import nadam\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0323 23:33:37.199226 12168 deprecation_wrapper.py:119] From c:\\users\\alegzander\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0323 23:33:38.016031 12168 deprecation_wrapper.py:119] From c:\\users\\alegzander\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = load_model('hm_shallow_net.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 413,802\n",
      "Trainable params: 413,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the main body of a program: it takes a live feed, detects and classifies clothing object using our custom-made CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning on the camera\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "#prepearing the recording file\n",
    "writer = imageio.get_writer('clothing_detection.mp4')\n",
    "\n",
    "while True:\n",
    "    #reading the live feed\n",
    "    _, frame = video_capture.read()\n",
    "    #detecting and labeling clothing objects\n",
    "    frame = obj_detector(frame, cnn)\n",
    "    #displaying the output\n",
    "    cv2.imshow('Video', frame)\n",
    "    #writing the output to the video file\n",
    "    writer.append_data(frame)\n",
    "    #quit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "#turning-off the camera and shutting down the display windows \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
